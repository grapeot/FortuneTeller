#!/usr/bin/env python3
"""
æ€§èƒ½åˆ†æè„šæœ¬ï¼šé‡ç°æ•´ä¸ªç›¸é¢æµç¨‹å¹¶åˆ†ææ€§èƒ½ç“¶é¢ˆ

æµç¨‹ï¼š
1. åŠ è½½æµ‹è¯•å›¾ç‰‡
2. å›¾åƒå¤„ç†ï¼ˆæ¨¡æ‹ŸMediaPipeå¤„ç†ï¼‰
3. è°ƒç”¨LLM API
4. åˆ†æå„æ­¥éª¤è€—æ—¶
"""

import asyncio
import base64
import json
import os
import time
from pathlib import Path
from typing import Dict, Optional

import httpx
from dotenv import load_dotenv

load_dotenv()

# é…ç½®
AI_API_BASE = os.getenv("AI_API_BASE_URL", "https://space.ai-builders.com/backend/v1")
AI_TOKEN = os.getenv("AI_BUILDER_TOKEN") or os.getenv("VITE_AI_API_TOKEN", "")
TEST_IMAGE_PATH = Path(__file__).parent.parent / "test-assets" / "test-face-1.jpg"

# ç®€åŒ–çš„ç³»ç»Ÿpromptï¼ˆç”¨äºæµ‹è¯•ï¼‰
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­å›½ä¼ ç»Ÿé¢ç›¸å­¦çš„ç›¸é¢å…ˆç”Ÿã€‚æ­¤åˆ»æ­£å€¼2026å¹´ä¸™åˆé©¬å¹´æ–°æ˜¥ï¼Œä½ åœ¨åº™ä¼šä¸Šä¸ºæ¥å®¢çœ‹ç›¸ã€‚ä½ ä¼šæ”¶åˆ°æ¥è®¿è€…çš„é¢éƒ¨ç…§ç‰‡ä»¥åŠé¢éƒ¨æµ‹é‡æ•°æ®ã€‚è¯·æ ¹æ®ä½ å®é™…è§‚å¯Ÿåˆ°çš„é¢éƒ¨ç‰¹å¾ï¼Œç»™å‡ºä¸“ä¸šã€å…·ä½“çš„é¢ç›¸åˆ†æã€‚

ä¸¥æ ¼ç”¨JSONæ ¼å¼è¿”å›ï¼Œä¸è¦markdownä»£ç å—ï¼š
{"face": "é¢ç›¸è§‚å¯Ÿâ€”â€”", "career": "äº‹ä¸šå»ºè®®ã€‚", "blessing": "æ–°æ˜¥ç¥è¯­ï¼"}"""


class Profiler:
    """æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        self.timings: Dict[str, float] = {}
        self.start_time: Optional[float] = None
        
    def start(self):
        """å¼€å§‹è®¡æ—¶"""
        self.start_time = time.time()
        
    def mark(self, name: str):
        """æ ‡è®°ä¸€ä¸ªæ—¶é—´ç‚¹"""
        if self.start_time is None:
            self.start_time = time.time()
        elapsed = time.time() - self.start_time
        self.timings[name] = elapsed
        print(f"â±ï¸  {name}: {elapsed:.3f}s")
        
    def get_report(self) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        if not self.timings:
            return "æ— è®¡æ—¶æ•°æ®"
        
        report = ["\n" + "="*60]
        report.append("æ€§èƒ½åˆ†ææŠ¥å‘Š")
        report.append("="*60 + "\n")
        
        prev_time = 0
        for name, elapsed in self.timings.items():
            step_time = elapsed - prev_time
            percentage = (step_time / elapsed * 100) if elapsed > 0 else 0
            report.append(f"{name:30s} {step_time:8.3f}s ({percentage:5.1f}%)")
            prev_time = elapsed
        
        total = max(self.timings.values()) if self.timings else 0
        report.append("-" * 60)
        report.append(f"{'æ€»è®¡':30s} {total:8.3f}s")
        report.append("="*60 + "\n")
        
        return "\n".join(report)


async def load_test_image() -> tuple[str, float]:
    """åŠ è½½æµ‹è¯•å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64"""
    start = time.time()
    
    if not TEST_IMAGE_PATH.exists():
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡ï¼ˆ1x1åƒç´ ï¼‰
        from PIL import Image
        img = Image.new('RGB', (640, 480), color='gray')
        img.save(TEST_IMAGE_PATH, 'JPEG')
        print(f"âš ï¸  åˆ›å»ºäº†æµ‹è¯•å›¾ç‰‡: {TEST_IMAGE_PATH}")
    
    with open(TEST_IMAGE_PATH, 'rb') as f:
        image_bytes = f.read()
    
    image_b64 = base64.b64encode(image_bytes).decode('utf-8')
    data_url = f"data:image/jpeg;base64,{image_b64}"
    
    elapsed = time.time() - start
    return data_url, elapsed


async def simulate_image_processing(image_data_url: str) -> tuple[dict, float]:
    """æ¨¡æ‹Ÿå›¾åƒå¤„ç†ï¼ˆMediaPipeé¢éƒ¨æ£€æµ‹å’Œæ ‡æ³¨ï¼‰"""
    start = time.time()
    
    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´ï¼ˆå®é™…MediaPipeå¤„ç†é€šå¸¸åœ¨100-300msï¼‰
    await asyncio.sleep(0.2)
    
    # æ¨¡æ‹Ÿæµ‹é‡æ•°æ®
    measurements = {
        "ä¸‰åœæ¯”ä¾‹": {"ä¸Šåœ": 0.33, "ä¸­åœ": 0.34, "ä¸‹åœ": 0.33},
        "è„¸å‹": "æ¤­åœ†å½¢",
        "äº”å®˜ç‰¹å¾": "æ ‡å‡†",
    }
    
    elapsed = time.time() - start
    return measurements, elapsed


async def call_llm_api(image_data_url: str, measurements: dict) -> tuple[dict, float]:
    """è°ƒç”¨LLM API"""
    start = time.time()
    
    if not AI_TOKEN:
        raise ValueError("AI_BUILDER_TOKEN æœªé…ç½®")
    
    user_content = [
        {
            "type": "image_url",
            "image_url": {"url": image_data_url},
        },
        {
            "type": "text",
            "text": f"è¯·ä»”ç»†è§‚å¯Ÿè¿™ä½è´µå®¢çš„é¢ç›¸ã€‚\n\næµ‹é‡æ•°æ®ï¼š{json.dumps(measurements, ensure_ascii=False)}\n\nè¯·æ ¹æ®ä½ çš„é¢ç›¸å­¦çŸ¥è¯†å’Œå®é™…è§‚å¯Ÿç»™å‡ºå…·ä½“çš„è®ºæ–­ã€‚",
        },
    ]
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        resp = await client.post(
            f"{AI_API_BASE}/chat/completions",
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {AI_TOKEN}",
            },
            json={
                "model": "grok-4-fast",  # ä½¿ç”¨grokæ¨¡å‹
                "messages": [
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_content},
                ],
                "temperature": 1.0,
                "max_tokens": 1200,
            },
        )
        resp.raise_for_status()
        
        data = resp.json()
        text = (data.get("choices") or [{}])[0].get("message", {}).get("content", "").strip()
        
        # è§£æJSONå“åº”
        json_str = text.replace("```json", "").replace("```", "").strip()
        result = json.loads(json_str)
    
    elapsed = time.time() - start
    return result, elapsed


async def main():
    """ä¸»æµç¨‹"""
    profiler = Profiler()
    profiler.start()
    
    print("ğŸš€ å¼€å§‹æ€§èƒ½åˆ†æ...\n")
    
    try:
        # æ­¥éª¤1: åŠ è½½å›¾ç‰‡
        print("ğŸ“¸ æ­¥éª¤1: åŠ è½½æµ‹è¯•å›¾ç‰‡...")
        image_data_url, load_time = await load_test_image()
        profiler.mark(f"1. åŠ è½½å›¾ç‰‡ ({load_time*1000:.0f}ms)")
        
        # æ­¥éª¤2: å›¾åƒå¤„ç†
        print("\nğŸ–¼ï¸  æ­¥éª¤2: å›¾åƒå¤„ç†ï¼ˆæ¨¡æ‹ŸMediaPipeï¼‰...")
        measurements, process_time = await simulate_image_processing(image_data_url)
        profiler.mark(f"2. å›¾åƒå¤„ç† ({process_time*1000:.0f}ms)")
        
        # æ­¥éª¤3: è°ƒç”¨LLM API
        print("\nğŸ¤– æ­¥éª¤3: è°ƒç”¨LLM API...")
        result, api_time = await call_llm_api(image_data_url, measurements)
        profiler.mark(f"3. LLM APIè°ƒç”¨ ({api_time*1000:.0f}ms)")
        
        # æ­¥éª¤4: ç»“æœå¤„ç†
        print("\nâœ… æ­¥éª¤4: ç»“æœå¤„ç†...")
        await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿç»“æœå¤„ç†æ—¶é—´
        profiler.mark("4. ç»“æœå¤„ç†")
        
        # è¾“å‡ºç»“æœ
        print("\n" + "="*60)
        print("ç›¸é¢ç»“æœ:")
        print("="*60)
        print(f"é¢ç›¸: {result.get('face', 'N/A')}")
        print(f"äº‹ä¸š: {result.get('career', 'N/A')}")
        print(f"ç¥è¯­: {result.get('blessing', 'N/A')}")
        
        # ç”ŸæˆæŠ¥å‘Š
        print(profiler.get_report())
        
        # æ€§èƒ½åˆ†æ
        print("\nğŸ“Š æ€§èƒ½åˆ†æ:")
        print("-" * 60)
        total_time = max(profiler.timings.values())
        
        if api_time > total_time * 0.7:
            print("âš ï¸  ç“¶é¢ˆ: LLM APIè°ƒç”¨å ç”¨äº†å¤§éƒ¨åˆ†æ—¶é—´")
            print("   å»ºè®®: è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹æˆ–ä¼˜åŒ–prompt")
        elif process_time > total_time * 0.3:
            print("âš ï¸  ç“¶é¢ˆ: å›¾åƒå¤„ç†å ç”¨äº†è¾ƒå¤šæ—¶é—´")
            print("   å»ºè®®: æ£€æŸ¥MediaPipeé…ç½®æˆ–ä½¿ç”¨æ›´å¿«çš„æ£€æµ‹æ¨¡å‹")
        else:
            print("âœ… å„æ­¥éª¤æ—¶é—´åˆ†é…è¾ƒä¸ºå‡è¡¡")
        
        print(f"\næ€»è€—æ—¶: {total_time:.3f}s")
        if total_time > 5:
            print("âš ï¸  æ€»è€—æ—¶è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–")
        elif total_time > 3:
            print("â„¹ï¸  æ€»è€—æ—¶é€‚ä¸­")
        else:
            print("âœ… æ€»è€—æ—¶è¾ƒçŸ­")
            
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        profiler.mark("é”™è¯¯å‘ç”Ÿ")
        print(profiler.get_report())


if __name__ == "__main__":
    asyncio.run(main())
