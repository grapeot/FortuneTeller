# 面相分析流水线性能分析报告

## 测试环境

- API: `https://space.ai-builders.com/backend/v1`
- 模型: `grok-4-fast`
- 测试图片: `test-assets/test-face-1.jpg` (545 KB)

## 各步骤耗时

| 步骤 | 耗时 | 说明 |
|------|------|------|
| 图片加载 + Base64 编码 | 1 ms | 可忽略 |
| **Grok 模型调用** | **4,291 ms** | HTTP 请求 4,257 ms，JSON 解析 <1 ms |
| **AI 图片编辑 (像素化)** | **41,998 ms** | 几乎全部耗时在远程 API |
| 提取图片数据 | 3 ms | 可忽略 |
| 本地 PIL 缩放 | 41 ms | 可忽略 |
| **并行执行总耗时** | **46,370 ms** | 受限于最慢的像素化步骤 |
| 前端最小动画时长 | 15,000 ms | 硬编码值 |

## 瓶颈分析

当前前端通过 `Promise.all` 并行执行三个任务：
1. Grok 面相分析 (~4 秒)
2. AI 像素化头像生成 (~42 秒)
3. 最小动画计时器 (15 秒)

结果展示必须等**全部三个任务完成**才会触发。因此用户实际等待时间 = max(4s, 42s, 15s) = **42 秒**。

**核心瓶颈是 AI 图片编辑 API**：该 API 需要用 AI 生成像素风格头像，属于 AI 图片生成任务，耗时 40-46 秒，这是远程 API 的固有延迟，无法通过本地优化解决。

Grok 模型调用只需 4-5 秒，结果早已就绪，却被像素化任务阻塞。

## 已实施的优化

### 解耦像素化与结果展示（低风险、高收益）

**问题**：`Promise.all` 将像素化和面相分析绑定，用户必须等 42 秒才能看到实际上 4 秒就出来的分析结果。

**方案**：将像素化头像的获取从 `Promise.all` 中移出，面相结果一出来就立即展示。像素化头像在后台异步加载，完成后自动更新 UI。

**效果**：用户等待时间从 ~42 秒降至 ~5 秒（Grok 调用时间 + 最小动画时长取较大者）。最小动画时长也从 15 秒降至 5 秒。

**风险评估**：低。`ResultOverlay` 组件已经能处理 `pixelatedImage` 为 `null` 的情况，分享功能中像素化图片也是可选的。唯一的变化是用户先看到没有像素头像的结果，头像稍后出现。

## 剩余可探索的优化方向

1. **像素化 API 缓存**：如果同一用户多次分析，可以缓存像素化结果，避免重复调用。
2. **降低像素化图片的 AI 生成尺寸**：当前请求 1024x1024，最终只用 64x64 像素。可以尝试请求更小的尺寸（如 256x256）看是否能加速。
3. **替代方案**：如果像素化只是为了隐私保护，可以考虑纯本地的像素化处理（直接对原图 PIL 缩放），完全跳过 AI 图片生成，耗时可降至毫秒级。但这样会失去 AI 生成的像素风格美感。

---

## 二维码分享链路专项分析（2026-02-15）

### 分析目标

用户反馈“扫码进入 `/share/{id}` 感觉慢”，希望定位是：
1) 后端接口慢，还是 2) 页面加载/执行慢，还是 3) 两者叠加。

### 方法（可复现）

- 新增脚本：`tools/profile_share_latency.py`
- 示例命令：

```bash
source .venv/bin/activate && python tools/profile_share_latency.py --share-id 1603b64d --runs 3
```

- 测试维度：
  - `GET /share/{id}`（页面 HTML）
  - `GET /api/share/{id}`（分享数据）
  - `POST /api/analysis/l2`（详版分析）
  - 页面 HTML 引用的 JS/CSS/字体资源（数量、体积、最慢项）

### 实测结果（`https://space.ai-builders.com`）

| 项目 | 平均总耗时 | 平均 TTFB |
|------|------------|-----------|
| `/share/1603b64d` | 0.5586s | 0.5514s |
| `/api/share/1603b64d` | 0.6924s | 0.6846s |
| `POST /api/analysis/l2` | 0.5633s | 0.5632s |

资源画像：
- 发现 `_next` 前端资源 **15 个**
- 总下载体积约 **730,602 bytes (~713 KB)**
- 单文件最慢约 **0.80s**（`255-40a1ec71a4b96256.js`, 172 KB）
- 最大 JS 两个 chunk 均约 **172 KB** 级别

### 结论（Principle）

1. **接口本身不是主要瓶颈**：`/api/share` 与 `/api/analysis/l2` 都在 ~0.6-0.7s 量级。
2. **“扫码慢”的主因更接近前端加载与执行成本**：
   - `/share/{id}` 返回的是 Next 页面及其 `_next/static/chunks/*` 资源；
   - 资源总量在移动网络/中端手机上会放大成明显白屏或“可交互前等待”。
3. **慢感是“端侧成本”而非单一 API 慢**：尤其在手机端，JS 下载 + 解析 + 执行 + 首屏渲染是关键路径。

### 下一步建议（按收益排序）

1. **缩减 share 首屏 JS**：
   - 针对 `/share/{id}` 做更激进的路由级代码拆分；
   - 非首屏逻辑（邮箱订阅、L2扩展信息）延后加载。
2. **强化缓存策略**：
   - 为 `_next/static/*` 设置长期强缓存（immutable）；
   - 确认 CDN 命中率与边缘回源耗时。
3. **首屏先渲染“最小可用态”**：
   - 先显示核心文本和轮廓图骨架，再补二维码/L2等次级内容。
4. **继续做设备分层 profiling**：
   - 建议补一轮真机（iOS/Android）性能采样，记录 TTI/FCP，而不仅是 HTTP 耗时。
